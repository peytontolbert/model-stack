## Program Examples (Backends and Use Cases)

This directory hosts example programs (each provides a ProgramGraph backend, retrieval policy, and optional probes) that run on top of the Program‚ÄëConditioned Adapter (PCA) core.

APIs (OpenAPI/gRPC)
- Program: api_grounded_qa
- Entities: endpoints, operations, schemas, examples
- Artifacts: OpenAPI files, protobufs, example requests, changelogs
- Probes: JSON‚ÄëSchema validation, contract diffs, replay of golden requests
- Tasks:
  - Change‚Äëimpact: diff spec versions ‚Üí list breaking changes and affected clients
  - Grounded endpoint QA: synthesize request/response with schema validation and citations

CLIs / Manpages
- Program: cli_pipeline_planner
- Entities: commands, subcommands, flags, env vars
- Artifacts: manpages, --help outputs, example scripts
- Probes: dry‚Äërun execution, exit codes, argument parsing checks
- Tasks:
  - Command construction from task descriptions
  - Pipeline recipes across multiple commands with validated dry‚Äëruns
  - Migration helpers: map deprecated flags to new equivalents with citations

DAGs / Orchestrators
- Program: dag_debugger
- Entities: tasks, operators, datasets, schedules
- Artifacts: DAG definitions, runtime logs, task metadata
- Probes: dry‚Äërun, dependency resolution, lineage checks
- Tasks:
  - DAG debugging: explain failed task via dependency/contract evidence
  - Execution planning: propose parallelization/caching opportunities

Microservices / Messaging
- Program: svc_messaging_ops
- Entities: services, topics/queues, message types, consumers/producers
- Artifacts: AsyncAPI/specs, schemas, topology maps, error logs
- Probes: schema compatibility checks, DLQ scans, retry config simulation
- Tasks:
  - Contract gaps: detect missing producers/consumers or schema drifts
  - Retry/dead‚Äëletter planning: propose safe backoff/timeout configs
  - SLO guidance: map symptoms to service‚Äëspecific reliability levers

ML / Feature Stores
- Program: feature_store_qa
- Entities: features, sources, transforms, training jobs
- Artifacts: feature specs, training configs, lineage graphs
- Probes: schema checks, offline/online parity, drift tests
- Tasks:
  - Feature lineage: trace features to sources and transformations
  - Training pipeline QA: verify schema/contract adherence end‚Äëto‚Äëend
  - Drift diagnostics: propose probes and mitigations

Data Integration (ETL/ELT)
- Program: etl_integrator
- Entities: sources, transforms, joins, schedules, SLAs
- Artifacts: mapping specs, SQL scripts, lineage, SLA docs
- Probes: schema validation, EXPLAIN plans, SLA simulators
- Tasks:
  - Mapping assistants: propose joins/transforms with schema checks
  - SLA planning: detect bottlenecks and propose schedule changes
  - Backfill plans: safe, chunked backfills with constraints

Security / SOAR
- Program: soar_playbooks
- Entities: playbooks, actions, rules, integrations
- Artifacts: runbooks, connector specs, alert samples
- Probes: dry‚Äërun actions, policy lint, rule simulation
- Tasks:
  - Playbook validation: check steps against tool contracts
  - Alert triage: map rules/signatures to remediation tasks
  - Policy rollout: generate incremental deployment plans with guardrails

Scientific / HPC Schedulers
- Program: hpc_scheduler_planner
- Entities: queues, constraints, jobs, nodes
- Artifacts: SLURM/LSF configs, job scripts, performance metrics
- Probes: dry‚Äërun submit, resource fit checks, queue policy simulation
- Tasks:
  - Job planning: resource requests, constraints, queue selection
  - DAG‚Äëto‚ÄëSLURM translation: grounded script generation with checks
  - Performance hints: propose parallelization and I/O layouts

Multi‚ÄëProgram Unions (Software Development domain)
- Program: repo_multiK_grounded_qa
  - Compose: K repositories (client/server/infra)
  - Tasks: answer spanning repos with interface table proving symbol ‚Üî endpoint ‚Üî config links; multi‚Äërepo citations (repo:file:line)
- Program: repo_interface_mapper
  - Compose: K repositories forming a system
  - Tasks: map cross‚Äërepo contracts (types/endpoints/events) and output a ContractMap table; verify with a golden‚Äëpath toy integration check
- Program: agent_contract_guard
  - Compose: K repositories with interfaces and service contracts
  - Tasks: detect cross‚Äërepo interface incompatibilities; emit ContractGuardReport and FixPlan; validate with a ToyIntegrationCheck
- Program: dev_union_repo_api_db_ci
  - Compose: Code repo (Git) + OpenAPI + DB schema + CI configs
  - Tasks: End‚Äëto‚Äëend ‚Äúimplement/modify endpoint X‚Äù plan (code stubs + SQL + CI) and ‚Äúwhat breaks if we rename column Y?‚Äù with grounded citations
- Program: dev_union_repo_k8s_configs
  - Compose: Repo + Helm/K8s manifests + service‚Äëmesh policy
  - Tasks: Safe rollout plan (resources/limits/probes) and config/code drift detection + fixes
- Program: dev_union_repo_tests_coverage
  - Compose: Repo + test results + coverage + flaky logs
  - Tasks: Minimal test plan for touched modules (evidence: coverage hits) and flaky test triage with likely root cause and stabilizing steps

LLM‚Äëin‚Äëthe‚Äëloop Primitives (PCA roles)
- Program: webdom_single_arxiv
  - IO: ArxivBundle{ids|urls|query} ‚Üí PaperDOM{title, authors[], abstract, sections[], references[], citations[]}
  - Probes/Œò: each DOM section has anchored citations to fetched HTML/text; size/structure checks
  - Notes: uses Selenium headless Chromium to fetch pages from [arXiv](https://arxiv.org/). Install: `pip install selenium webdriver-manager`; ensure Chrome/Chromium installed.
- Program: llm_as_router
  - IO: Subgoal{text} + CapabilityIndex ‚Üí RouteDecision{program_id, confidence, rationale}
  - Probes/Œò: route‚Äëregret via hindsight after verification; compare chosen route vs best verified route
  - Tasks: select most promising program(s) for a goal under budget constraints with rationale and fallbacks
- Program: router_meta_capability_select
  - IO: Subgoal{intent, repo, codegraph_slice?, constraints, budget} ‚Üí Binding{program_id, adapter_mix{(adapter_id, w, rank)‚Ä¶}}
  - Probes/Œò: interface match to program‚Äôs schema; budget feasibility; adapter policy gates (mix_top_k, ranks)
  - Tasks: choose program and adapter mixture per subgoal; learn from verified passes (recent_pass_boost)
- Program: llm_as_agent
  - IO: Tools/Capabilities + Goal ‚Üí ActionPlan{steps[], rationales[]} + Trace
  - Probes/Œò: step outputs validated by downstream program verifiers; ensure contracts/preconditions satisfied
  - Tasks: decompose and invoke tool‚Äëlike capabilities with typed arguments while respecting budgets and policies
- Program: llm_as_planner (optional)
  - IO: Goal ‚Üí TypedDAG{subgoals[], edges[]}
  - Probes/Œò: schema/type checks against Œì; replay viability under budget
  - Tasks: produce DAG of subgoals with capability matches and minimal budgets
- Program: llm_as_judge (optional)
  - IO: ProgramOutputs ‚Üí Verdict{ok, summary, citations}
  - Probes/Œò: cross‚Äëchecks with lints/tests/compile; disagreements logged as counter‚Äëevidence
  - Tasks: augment/verbalize verifier results with human‚Äëreadable rationale and policy mapping
- Program: llm_as_packer (optional)
  - IO: Sources + Constraints ‚Üí PackedWindows{slices[]}
  - Probes/Œò: citation density, hit rate vs ground truth windows
  - Tasks: choose evidence windows (diffs, spans, API slices) to maximize verifier pass per token

Notes
- Each program provides a ProgramGraph implementation and (optionally) probes that the runner can use to verify, cite, or repair answers.
- Use `examples/program_conditioned_adapter/run.py --pg-backend <module:Factory>` to load a backend; the PCA core remains program‚Äëagnostic.

Software Development Program Examples
- Warehouse DAG Diagnose (ETL/DBT/Airflow)
  - Name: warehouse_multi_dag_diagnose
  - Program: U = DAG runs/logs; O = SLA root-causes + fix plan; Œò = replay on sample DAG and green task exits.
  - Tasks: diagnose SLA misses and propose actionable fixes with citations.
- Change Summarizer (diff-aware, symbol-linked)
  - Name: summarize_single_repo_change
  - Program: U = diffs, graph slices, tests touched; O = ChangeSummary{headline, risk_factors[], api_changes[], test_impacts[], citations[]}; Œò = every bullet has resolvable citations; size/structure limits.
  - Tasks: produce PR-ready summaries with anchors; optional Narrative.md for human review.
- Code Entity Graph (single repo)
  - Name: graph_single_code_entity
  - Program: U = files/symbols; E = imports/calls; O = symbols, edges, tests, owners, api_surface; Œò = parser success rate, import acyclicity per package, symbol‚Üífile existence, test discovery sanity.
  - Tasks: materialize CodeGraph caches; serve CodeGraphSlice given symbols and radius.
- CI‚ÄëFailure Triage (multi‚Äërepo + logs)
  - Name: ci_multi_triage
  - Program: U = commits, PRs, CI jobs, build/test logs; E = PR‚Üíjob, commit‚Üíartifact; O = failing tests, error types; T = step logs + stack traces; Œò = failure classifier + fix‚Äësuggestion verifier.
  - Tasks: grounded failure explanation; ‚Äúnearest fix‚Äù retrieval; patch sketch with citations to failing lines and prior fixes.
  - Adapter context: build logs + failing test windows + changed files.
  - Eval: retro‚Äëtriage accuracy, patch acceptance rate.
- PR‚ÄëDiff Review with Policy
  - Name: repo_single_pr_review
  - Program: U = diffs, CODEOWNERS, linters; C = style/security/complexity policy; O = lints/coverage deltas; Œò = policy checker + counterexample miner.
  - Tasks: comment generation with path:line citations; show policy violations; test suggestions for changed public APIs.
  - Eval: policy‚Äëviolation precision/recall, developer acceptance.
- Test Gap Discovery & Targeted Test Generation
  - Name: repo_single_testgen
  - Program: U = code, tests, coverage map; E = callgraph (prod‚Üîtest); O = uncovered public surface; Œò = generator + pytest verifier.
  - Tasks: rank uncovered critical functions; generate minimal tests; verify via local runner; export per‚Äëmodule adapters.
  - Eval: new coverage, flake rate, mutation‚Äëscore uplift.
- Security Advisory & SAST‚ÄëGrounded Patching
  - Name: repo_multi20_sec_patch
  - Program: U = code + SBOM + advisories (CVEs), SAST outputs; E = dep graph; O = vulnerable ranges; T = scanner traces; Œò = advisory‚Üícallsite mapper + patch verifier.
  - Tasks: locate exploitation surfaces; propose patches; update dependencies with ripple‚Äëcheck to build/test.
  - Eval: vuln recall@k, build pass rate post‚Äëpatch, diff locality.
- API Usage Migration (v1‚Üív2)
  - Name: repo_single_api_migrate
  - Program: U = code, old/new API docs/changelogs; E = ref map old‚Üínew, callsites; C = migration rules; Œò = matcher + rewrite synthesizer + compile/test verifier.
  - Tasks: find callsites; propose rewrites; produce PR with cited diffs.
  - Eval: migration success rate, tests green on first try.
- Performance Regression Explainer
  - Name: repo_single_perf_explain
  - Program: U = benchmarks, profiles, code; O = perf deltas; T = profiler traces; Œò = hot‚Äëpath localizer + regressor explainer.
  - Tasks: link regression to commit diff + code paths; propose micro‚Äëpatches with citations.
  - Eval: % regressions with actionable RCA, perf regained.
- Runtime Error Crash Triage (Prod logs)
  - Name: logs_single_crash_triage
  - Program: U = logs/stack traces, build info; E = symbolication map; O = error clusters; T = trace spans; Œò = clusterer + ‚Äúclosest prior fix‚Äù retriever.
  - Tasks: cluster by signature; map to source regions; output RCA with repo citations; link to prior fixes.
  - Eval: mean time to RCA, duplicate bug rate.
- Database Schema & Query Assistant
  - Name: sql_single_grounded_qa
  - Program: U = DDL, ERDs, migrations; E = FK graph; O = query plans; T = slow query logs; Œò = plan analyzer + index advisor.
  - Tasks: grounded SQL Q&A; safe query synthesis; migration impact analysis.
  - Eval: plan cost reduction; correctness on DB eval set.
- Build System Doctor (Bazel/Make/CMake)
  - Name: build_single_doctor
  - Program: U = build files, cache, action graph; E = target deps; O = cache misses, action times; T = build logs; Œò = invalidation explainer + rule tuner.
  - Tasks: explain slow/fragile targets; propose rule fixes; cite BUILD files.
  - Eval: cache hit rate; rebuild time reduction.
- Dependency Hygiene & Supply‚ÄëChain
  - Name: deps_multi_policy
  - Program: U = lockfiles/SBOM; E = transitive graph; C = org policy (licenses/versions); O = violations; Œò = resolver proposing compliant replacements.
  - Tasks: identify policy breaks; propose minimal diffs; smoke build.
  - Eval: policy conformance; PR merge latency.
- Notebook/Docs ‚Üî Code Consistency
  - Name: notebook_single_sync
  - Program: U = notebooks, README, tutorials, code; E = example‚ÜíAPI links; O = drift; Œò = runnable‚Äësnippet verifier.
  - Tasks: detect stale docs; generate updated examples with citations.
  - Eval: example pass rate in CI; doc PR churn decrease.
- Issue Triage (GitHub/Jira) with Evidence Lift
  - Name: issues_multi_triage
  - Program: U = issues, labels, commits; E = issue‚Üîcommit/test links; O = duplicates, missing repro; T = linked logs; Œò = deduper + repro‚Äësteps synthesizer.
  - Tasks: dedupe; propose repro steps; owner routing.
  - Eval: duplicate closure time; first‚Äëresponse quality.
- Cross‚ÄëRepo Architecture Map & Impact Analysis
  - Name: arch_multi20_impact
  - Program: U = many repos, service manifests, RPC/REST specs; E = service call graph; O = blast radius; Œò = impact estimator.
  - Tasks: ‚ÄúIf I change X, what breaks?‚Äù with downstream citations.
  - Eval: precision of impacted targets; rollback avoidance.
- LLM‚Äëin‚Äëthe‚ÄëLoop Refactor Planning
  - Name: repo_single_refactor_plan
  - Program: U = code + tests; E = cohesion/coupling graph; O = code smells; Œò = refactor planner + risk scorer + test selector.
  - Tasks: staged refactor plan with guardrails; per‚Äëstage patches/tests with citations.
  - Eval: refactor acceptance; defect escape rate.
- Frontend UI Snapshot & Visual Diff QA
  - Name: ui_single_visual_qa
  - Program: U = storybook stories, screenshots; O = visual diffs; T = rendering logs; Œò = perceptual diff explainer + CSS/DOM patch suggester.
  - Tasks: explain DOM/CSS lineage for diffs; propose fix.
  - Eval: false‚Äëpositive reduction; fix time.
- Data‚ÄëPipeline/DAG Grounded Assistant (Airflow/Prefect)
  - Name: dag_single_operator_qa
  - Program: U = DAGs, operators, logs; E = task deps; O = task failures/slowness; T = run logs; Œò = operator doctor + SLA planner.
  - Tasks: diagnose failing task; propose operator config fix with citations.
  - Eval: SLA adherence; re‚Äërun success.

Scaffolding pattern
- ProgramGraph builder for entities/edges; hashed channels to produce z and subgraph z_sub.
- Two selectors: fast heuristic and evidence‚Äëscored.
- Packing utilities: pack_heads and pack_windows.
- Adapters: base prior + on‚Äëthe‚Äëfly subgraph adapters; target‚Äëweight presets.
- Verifiers (Œò): pytest/compile/lints/schema/log replay; gate verified buffer for self‚Äëtune.
- CLIs per example:
  - examples/programs/<name>/build.py
  - examples/programs/<name>/run_<backend>_enhanced.py
  - examples/programs/<name>/self_tune.py

AGI‚ÄëStyle Meta‚ÄëProgram (Coding AGI)
- Meta‚Äëprogram M = ‚ü®P, Œì, R, Œ†, Œõ, Œû‚ü© where:
  - P: installed programs {P1..Pn} (e.g., PR‚Äëreview, CI‚Äëtriage, SQL‚ÄëQA)
  - Œì: typed interfaces/adapters for inter‚Äëprogram messaging (IO schemas, effect contracts)
  - R: router that selects/combines programs (policy over embeddings, graphs, evidence)
  - Œ†: planner/binder that decomposes tasks and binds subgoals to Pi with budgets
  - Œõ: learning loop (self‚Äëtune) using verifiers Œòi as reward/certification
  - Œû: global memory (episodic/semantic/procedural) with immutable evidence ledger
- Minimal orchestration loop (planner ‚Üí binder ‚Üí executor ‚Üí verifier ‚Üí tutor):
  - Receive goal ‚Üí Œ† decomposes into typed subgoals
  - Bind subgoals to programs with budgets ‚Üí execute (pack, run, cite)
  - Verify via Œòi ‚Üí on pass, Œõ updates adapters/memory; on fail, re‚Äëplan with bounded retries
- Key rules:
  - Only verifiers write to memory (no unverifiable beliefs)
  - Typed results per program (e.g., ReviewComments[], PatchDiff, SQLPlanAdvice) to chain safely
  - Budgets are first‚Äëclass (tokens, wall‚Äëtime, CI minutes); failures consume budget and trigger re‚Äëplanning
- Program composition (interfaces & contracts):
  - Program exposes capabilities with TypedIO signatures, cost models, pre/post‚Äëconditions
  - Router selects plan; Planner binds subgoals to programs
- Router & adapter mixing:
  - Static capability index (embed capability cards + verified exemplars)
  - Contextual routing: score sim(goal, capability) + evidence_prior
  - Adapter mixing: blend subgraph adapters from relevant programs with rank caps; upweight programs whose verifiers passed in session
- Evidence‚Äëfirst memory (Œû):
  - Episodic: transcripts/artifacts/diffs with citations
  - Semantic: distilled facts promoted only after repeated verifier passes
  - Procedural: ‚Äúwhat worked‚Äù policies (router priors, packer heuristics, budgets)
  - All writes include verifier hash and provenance (repo path, CI job, commit)
- Self‚Äëtuning Œõ (only checks, no labels):
  - Unit: (goal, plan, packed windows, outputs, verdict, cost)
  - Objective: maximize verifier pass rate / minimize cost
  - Knobs: adapter ranks, packer windows, router priors, tool ordering
  - Method: offline policy eval + online small delta LoRAs per skill; merge after stability
- Safety & rollback:
  - Dry‚Äërun by default; real writes require actuation tokens and a green verifier chain
  - Non‚Äëdestructive diffs: patches as PRs with exact citations
  - Time‚Äëboxed retries and circuit breakers; degrade to best single program
  - Auditability: every action links to evidence in the ledger
- Minimal code skeleton:
  ```python
  # core/meta/runtime.py
  class MetaRuntime:
      def __init__(self, programs, router, planner, memory, tuner):
          self.P, self.R, self.Pi, self.Xi, self.L = programs, router, planner, memory, tuner
      def run(self, goal):
          plan = self.Pi.decompose(goal)
          bound = self.Pi.bind(plan, self.P, self.R, self.Xi.budgets(goal))
          for step in bound.steps:
              packed = step.program.pack(step.inputs, self.Xi.context(goal))
              outs = step.program.run(packed)
              verdict = step.program.verify(outs)
              self.Xi.record(goal, step, outs, verdict)
              if not verdict.ok:
                  bound = self.Pi.replan(goal, step, verdict, self.P, self.R, self.Xi)
                  continue
          self.L.update(self.Xi.verified_trajectories())
          return self.Xi.report(goal)
  ```
- Capability graph (installed skills):
  - Programs expose capabilities with typed IO signatures, cost models, and pre/post conditions.
  - Canonical starter capabilities:
    - PRReview: Diff ‚Üí ReviewComments[]
    - CITriage: FailLogs ‚Üí RootCause{files[], lines[], reason}
    - TestGen: APISurface ‚Üí Tests{files[], cmds[]}
    - RefactorPlan: CodeGraph ‚Üí Plan{stages[], risks[]}
    - SecPatch: SBOM+Advisories ‚Üí PatchDiff
    - PerfExplain: Profiles+Diff ‚Üí Hotpath{frames[], regressors[]}
    - SQLQA: Question ‚Üí SQL{query, safety, rationale}
    - CrashTriage: StackTraces ‚Üí ClusteredRCA
- Typed interfaces (Œì) with JSON Schemas (abridged example):
  ```json
  {
    "$id": "RootCause",
    "type": "object",
    "required": ["reason", "files", "lines", "evidence"],
    "properties": {
      "reason": {"type": "string"},
      "files": {"type": "array", "items": {"type": "string"}},
      "lines": {"type": "array", "items": {"type": "integer"}},
      "evidence": {"type": "array", "items": {"$ref": "Citation"}}
    }
  }
  ```
- Policies (budgets/safety/adapters/router) ‚Äî minimal excerpt:
  ```yaml
  budgets:
    default: {tokens: 64000, gpu_sec: 120, ci_min: 10}
    high_risk: {tokens: 96000, gpu_sec: 240, ci_min: 25}
  safety:
    actuation:
      apply_patch: requires: [tests_green, lints_ok, coverage_delta>=0]
      alter_schema: requires: [canary_env, rollback_plan, dba_approval]
  adapters:
    mix_top_k: 3
    ranks:
      repo_single_pr_review: 16
      ci_multi_triage: 8
      repo_single_testgen: 8
  router:
    boost_verified_recent_hours: 24
  ```
- Halt conditions:
  - Budget exhausted; repeated Œò‚Äëfails on same subgoal; missing preconditions (Œì violation); unsafe actuation.
- On‚Äëdisk layout (skeleton):
  ```
  coding_agi/
    core/
      runtime.py         # MetaRuntime
      planner.py         # Œ†
      router.py          # ùì°
      memory.py          # Œû
      tuner.py           # Œõ
      budgeter.py        # ùìë
      actuator.py        # Œ©
      interfaces/        # Œì JSON Schemas
    programs/            # Installed PCAs
      repo_single_pr_review/
      ci_multi_triage/
      repo_single_testgen/
      repo_single_refactor_plan/
      repo_multi20_sec_patch/
      repo_single_perf_explain/
      sql_single_grounded_qa/
      logs_single_crash_triage/
    packs/
      policies.yaml      # budgets, safety, ranks, gates
      capability_cards/  # router priors + exemplars
    cli/
      cap_build.py       # build base adapters
      cap_run.py         # execute goals end-to-end
      cap_self_tune.py   # Œõ on verified buffers
  ```
- Canonical flows:
  - A) Green‚Äëpatch from failing CI
    - CITriage: FailLogBundle ‚Üí RootCause{files, lines, evidence}
    - TestGen: APISurface(slice) ‚Üí Tests{files, cmds}
    - RefactorPlan: CodeGraphSlice ‚Üí PatchPlan + PatchDiff
    - Actuator: Open PR; run verifier chain; report
  - B) Feature request to refactor + tests
    - PRReview: Draft changes ‚Üí ReviewComments + risks
    - TestGen: New APISurface coverage ‚Üí Tests
    - PerfExplain: Profiles+Diff ‚Üí Hotpath guard
    - Actuator: PR + passing verifier chain
- Concrete composite to ship first:
  - Name: devops_multi_agent_maintainer
  - Included programs: repo_single_pr_review, ci_multi_triage, repo_single_testgen, deps_multi_policy, logs_single_crash_triage, repo_single_refactor_plan, sql_single_grounded_qa
  - Verifier chain: lints ‚Üí compile/build ‚Üí tests ‚Üí coverage/mutation ‚Üí policy gates ‚Üí (optional) staging canary
  - End‚Äëto‚Äëend tasks: take a bug report or failing CI, plan fix, propose patch, generate/adjust tests, tighten deps, explain root cause‚Äîwith citations and a mergeable PR
- KPIs:
  - Verifier‚Äëpass rate (per program & composite chains)
  - Patch acceptance rate and revert rate
  - MTTR for CI failures and prod crashes
  - Cost per successful action (tokens, GPU seconds, CI minutes)
  - Knowledge retention: re‚Äësolve rate on previously seen failure classes

Quickstart: run installed program smokes
- Agent PR Autofix:
  - python examples/program_conditioned_adapter/examples/agent_pr_autofix/run_smoke_example.py
- Agent Contract Guard:
  - python examples/program_conditioned_adapter/examples/agent_contract_guard/run_smoke_example.py
 - Dataset‚ÄëGrounded Training:
  - python examples/program_conditioned_adapter/examples/dataset_grounded_training/run_smoke_example.py
 - Speech‚Äëto‚ÄëSpeech Adapter:
  - python examples/program_conditioned_adapter/examples/speech_s2s_adapter/run_smoke_example.py
 - Docs Truth Enforcer:
  - python examples/program_conditioned_adapter/examples/docs_truth_enforcer/run_smoke_example.py
- Program Composer Agent:
  - python examples/program_conditioned_adapter/examples/program_composer_agent/run_smoke_example.py
- Self‚ÄëTune PCA:
  - python examples/program_conditioned_adapter/examples/self_tune_pca/run_smoke_example.py
- DOM Exec PCA (RPA):
  - python examples/program_conditioned_adapter/examples/dom_exec_pca/run_smoke_example.py
- Hypothesis Runner PCA:
  - python examples/program_conditioned_adapter/examples/hypothesis_runner_pca/run_smoke_example.py
- Temporal State Adapter:
  - python examples/program_conditioned_adapter/examples/temporal_state_adapter/run_smoke_example.py
- Counterfactual Adapter:
  - python examples/program_conditioned_adapter/examples/counterfactual_adapter/run_smoke_example.py
- Proof‚ÄëCarrying Adapter:
  - python examples/program_conditioned_adapter/examples/proof_carrying_adapter/run_smoke_example.py
- Tool Policy Adapter:
  - python examples/program_conditioned_adapter/examples/tool_policy_adapter/run_smoke_example.py
- Calibrated Decoder Adapter:
  - python examples/program_conditioned_adapter/examples/calibrated_decoder_adapter/run_smoke_example.py
- Skill Shard Distiller:
  - python examples/program_conditioned_adapter/examples/skill_shard_distiller/run_smoke_example.py
- Multi‚ÄëRepo Interface Mapper:
  - python examples/program_conditioned_adapter/examples/repo_interface_mapper/run_smoke_example.py
- PR Review:
  - python examples/program_conditioned_adapter/examples/repo_single_pr_review/run_smoke_example.py
- Test Generation:
  - python examples/program_conditioned_adapter/examples/repo_single_testgen/run_smoke_example.py
- CI Failure Triage:
  - python examples/program_conditioned_adapter/examples/ci_multi_triage/run_smoke_example.py
- Refactor Plan:
  - python examples/program_conditioned_adapter/examples/repo_single_refactor_plan/run_smoke_example.py
- Deps Policy:
  - python examples/program_conditioned_adapter/examples/deps_multi_policy/run_smoke_example.py
- Crash Triage:
  - python examples/program_conditioned_adapter/examples/logs_single_crash_triage/run_smoke_example.py
- API Migrate:
  - python examples/program_conditioned_adapter/examples/repo_single_api_migrate/run_smoke_example.py
- Perf Explain:
  - python examples/program_conditioned_adapter/examples/repo_single_perf_explain/run_smoke_example.py
- SQL Grounded QA:
  - python examples/program_conditioned_adapter/examples/sql_single_grounded_qa/run_smoke_example.py
- Notebook Sync:
  - python examples/program_conditioned_adapter/examples/notebook_single_sync/run_smoke_example.py

Coding AGI example (meta‚Äëprogram)
- Location: examples/program_conditioned_adapter/examples/coding_agi/core
  - runtime.py: minimal MetaRuntime loop
  - planner.py: single‚Äëstep planner with simple retry
  - router.py: naive keyword router across installed programs
  - memory.py: evidence ledger with verified() filter
- Intent:
  - Demonstrates the orchestration shell that binds installed programs, routes a goal, executes, verifies, and records evidence.
  - Keep using individual program CLIs above for now; the meta‚Äëprogram illustrates structure and contracts for composition.

Tips
- Use --structured and --require-citations when running run.py directly to get typed outputs with anchored evidence.
- Prefer --code-recall-preset for code‚Äëcentric tasks (review, triage, testgen) to improve path:line citation density.
- Reuse adapters across runs by pointing --adapters-dir to the same artifacts directory for faster iteration.

### Program‚ÄëConditioned Adapter Taxonomy

1) Databases (SQL/OLAP/Vector)
- Adapters:
  - db_single_grounded_qa (schema‚Äëaware, query‚Äëcited answers)
  - db_change_planner (DDL/DML diff plans with rollbacks)
  - db_profile_router (route questions to the right DB/warehouse)
- Signals: schemas, foreign keys, indexes, stats, EXPLAIN plans, sample rows, lineage/owners
- Verifiers: dry‚Äërun queries, EXPLAIN shape matching, row counts / checksum comparisons

2) APIs / Microservices (REST, gRPC, GraphQL)
- Adapters:
  - api_grounded_qa (contract + example‚Äëdriven answers)
  - api_orchestrator_planner (multi‚Äëcall plans with rate‚Äëlimit guards)
  - api_change_guard (breaking‚Äëchange detector from OpenAPI diffs)
- Signals: OpenAPI/IDLs, examples, Postman collections, latency/error SLOs, auth scopes
- Verifiers: contract validation, schema conformance, replayable mock calls

3) CLIs / Toolchains
- Adapters:
  - cli_grounded_runner (flag‚Äëaware suggestions with manpages)
  - cli_batch_planner (compose safe command pipelines)
- Signals: --help/manpages, completion specs, exit codes, stdout/stderr exemplars
- Verifiers: sandbox execution, exit‚Äëcode + regex assertions, snapshot diffs

4) DAGs & Data Pipelines (Airflow/Prefect/DVC)
- Adapters:
  - dag_grounded_qa (task/source‚Äëof‚Äëtruth answers)
  - dag_change_planner (safe task edits, dependency impact)
- Signals: task graph, schedules, upstream/downstream, run logs, assets/lineage
- Verifiers: dry‚Äërun DAG parse, dependency reachability, test task replays

6) Logs / Telemetry / Traces (ELK, OpenTelemetry)
- Adapters:
  - telemetry_incident_summarizer
  - log_rootcause_router (signal‚Äëto‚Äëservice triage)
- Signals: metrics, spans, error clusters, golden signals (latency, errors, saturation)
- Verifiers: query reproducibility, time‚Äëbounded consistency, counterfactual checks

7) Notebooks & Repro Bundles (Jupyter, W&B/Runs)
- Adapters:
  - nb_grounded_qa (cell‚Äëcited answers)
  - experiment_compare_planner (A/B/C run comparison & next‚Äëstep plan)
- Signals: executed cell graph, outputs, environment YAML, run artifacts
- Verifiers: re‚Äëexecute minimal cells, metric threshold checks

8) Spreadsheets / BI / Reports
- Adapters:
  - sheet_formula_assistant (range‚Äëaware, versioned)
  - bi_card_explainer (dashboard element lineage to sources)
- Signals: sheets, named ranges, pivot/measure defs, data sources
- Verifiers: formula evaluation, sample recomputes, chart data parity

9) Document & Knowledge Graphs
- Adapters:
  - doc_citation_qa (page/line‚Äëcited grounding)
  - kg_path_reasoner (graph‚Äëconstrained multi‚Äëhop answers)
- Signals: chunked docs with anchors, KG nodes/edges, provenance metadata
- Verifiers: citation coverage, edge‚Äëpath validation, contradiction sweeps
 - Program: library_grounded_qa
   - Ask anything across a curated shelf; answer anchored to book:page:line with contradiction checks.
   - Signals: OCR‚Äôd PDFs/EPUBs, chapter/section graph, citation graph, footnotes, glossary/indices
   - Verifiers: page‚Äëbounded quote windows, cross‚Äësource agreement tests, edition disambiguation
   - Flow: Select ‚Üí Pack (page anchors) ‚Üí Adapt (shelf‚Äëconditioned) ‚Üí Generate ‚Üí Verify ‚Üí Cite
Tabular / Dataframe Grounding
- Program: data_table_grounded_qa
  - Signals: table schemas, samples, constraints, data contracts
  - Verifiers: in‚Äëprocess replay of code/SQL, shape/type assertions
  - Output: TableAnswer{answer, code, result_preview}

10) Messaging & Workflows (Email, Slack, Ticketing)
- Adapters:
  - ticket_triage_router (assign/label with SLA logic)
  - email_grounded_summarizer (thread‚Äëaware with links)
- Signals: threads, assignees, SLAs, labels, actions taken, checklists
- Verifiers: policy conformance, audit trail links, assignee availability

11) Browsers / DOM / RPA
- Adapters:
  - browser_dom_grounded_qa (selector‚Äëcited DOM answers)
  - rpa_flow_planner (deterministic macro plans)
- Signals: DOM trees, ARIA roles, screenshot hashes, stable selectors
- Verifiers: headless replay, visual diff thresholds, selector stability

12) Build/CI/Test Systems
- Adapters:
  - ci_failure_router (map failing test ‚Üî culprit commit/module)
  - test_gap_planner (coverage‚Äëguided test authoring)
- Signals: build graph, test results, coverage maps, flake profiles
- Verifiers: re‚Äërun failing shards, coverage deltas, determinism checks

13) Robotics / Simulation / Game Engines
- Adapters:
  - sim_policy_planner (scenario scripts with safety gates)
  - robot_task_grounder (URDF/env‚Äëaware task plans)
- Signals: URDF/SDF, scene graphs, sensor specs, reward curves, sim configs
- Verifiers: rollout metrics, safety constraints, reproducible seeds
 - Program: game_character_planner
   - Auto-plan a build, grind route, and respec path for a given playstyle; verify DPS/TTK vs boss profiles and route feasibility.

14) Media Pipelines (Video/Audio/CAD)
- Adapters:
  - media_render_planner (graph of transforms, codecs, budgets)
  - cad_param_qa (dimension‚Äëcited answers)
  - speech_s2s_adapter (ASR‚ÜíTTS with prosody/alignment/latency checks)
- Signals: timelines, node graphs, codec params, geometry/constraints
- Verifiers: hash‚Äëbased artifact checks, visual probes, parameter bounds

15) Geospatial / GIS
- Adapters:
  - gis_query_qa (layer/source‚Äëcited geospatial answers)
  - route_plan_validator (cost/safety/weather constraints)
- Signals: layers, CRS, topology, rasters, traffic/weather feeds
- Verifiers: topology rules, cross‚Äëlayer joins, route feasibility sims

### Core Utility Adapters (compose with any domain)

- Memory
  - memory_grounded_recall: consolidates verified Q/A + traces into a compact, citation‚Äërich cache the PCA can inject.
  - memory_incremental_distill: turns verified interactions into tiny add‚Äëon adapters (per‚Äëtopic/per‚Äëmodule).
  - skill_shard_distiller: converts every verified solve into a persistent skill‚Äëshard LoRA and updates the router; ships adapters/shards/*, router weights, and an eval curve.
- Temporal / Dynamics
  - temporal_state_adapter: encodes recent state transitions S_t‚Ä¶S_t‚àík so the model reasons over dynamics, not snapshots; signals: event logs, diffs, counters; verifiers: time‚Äëbounded invariants, rollback replay.
- Counterfactual / What‚ÄëIf
  - counterfactual_adapter: swaps contracts/policies {C‚ÜíC‚Ä≤} and re‚Äëcomputes ŒîŒ∏ to answer ‚Äúunder different rules‚Äù; signals: delta‚Äëcontracts; verifiers: consequence simulation, invariant maintenance.
- Proof‚ÄëCarrying
  - proof_carrying_adapter: stores minimal proof objects alongside ŒîŒ∏ (test IDs, pages, checksums) so any claim references a proof pointer; verifier: deterministic replay of proof pointer.
- Toolformer‚ÄëBinding
  - tool_policy_adapter: ŒîŒ∏ specialized to a whitelist of tools/APIs with schemas and rate limits; verifiers: mock replay, schema conformance, rate guard.
- Distribution‚ÄëAware Decoding
  - calibrated_decoder_adapter: adjusts token posterior calibration (ECE‚Üì); verifiers: held‚Äëout Brier/ECE + factuality checks.
- Routing
  - router_program_selector: choose correct program adapter (DB vs API vs Repo) using program signatures + confidence bounds.
  - router_task_selector: select task adapters (qa vs planner vs summarizer vs change_guard).
- Graphing
  - program_graph_builder: normalize any program to ‚ü®Entities, Edges, Artifacts, Contracts, State, Observables, Traces‚ü© and cache embeddings.
- Summarizing
  - program_state_summarizer: produce time‚Äëboxed, versioned digests of state/metrics with provenance anchors.

### Canonical PCA Interface (what every adapter implements)

- Select(): question‚Äëaware selection of subgraph/segments/windows from the program.
- Pack(): deterministic context packaging with anchored snippets (e.g., path:line or node:id).
- Embed(): multi‚Äëfactor embedding of program‚Äëspecific features (schemas, contracts, graphs, traces).
- Adapt(): produce or mix LoRA‚Äëlike deltas for the current LM layer targets (attention/MLP) with a stable gating schedule.
- Verify(): run program‚Äënative checks (dry‚Äërun SQL, API mock, DAG parse, test replay).
- Cite(): append anchors to every claim (files, schema tables, API endpoints, task nodes).
- Log(): emit minimal, privacy‚Äërespecting telemetry for reproducibility and distillation.

### Naming Patterns

- <program_domain>_<scope>_<task>
- Examples to ship:
  - repo_single_grounded_planner
  - db_single_grounded_qa
  - api_multi10_orchestrator_planner
  - dag_single_change_planner
  - iac_stack_risk_analyzer
  - browser_dom_grounded_qa
  - sheet_single_formula_assistant
  - telemetry_incident_summarizer

### Recommended Build Order

1) Router + Memory (foundational)
   - router_program_selector, memory_grounded_recall
2) DB + API (broadest utility)
   - db_single_grounded_qa, api_grounded_qa, with strict contract/schema verifiers
3) DAG + CI/Test (devops leverage)
   - dag_grounded_qa, ci_failure_router
4) Browser/RPA (end‚Äëto‚Äëend usability)
   - browser_dom_grounded_qa, rpa_flow_planner
5) Logs/Telemetry (oncall leverage)
   - telemetry_incident_summarizer, log_rootcause_router

Each domain shares the same PCA skeleton, so once you‚Äôve implemented Select/Pack/Embed/Adapt/Verify/Cite, new adapters are mostly feature mappers + verifiers.
