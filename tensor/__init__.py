from .norms import (
    RMSNorm,
    ScaleNorm,
    masked_rmsnorm,
    rmsnorm,
    layer_norm,
    mean_only_layer_norm,
    lp_norm,
    power_norm,
    chunked_rmsnorm,
    spectral_norm,
    weight_norm,
    orthogonalize,
    rolling_norm,
    online_rms,
)
from .mlp import MLP
from .activations import gelu, silu, bias_gelu, bias_silu
from .activations import fast_gelu, quick_gelu, mish, tanh_gelu, swiglu, geglu, reglu
from .masking import (
    build_causal_mask,
    build_padding_mask,
    apply_mask,
    broadcast_mask,
    build_sliding_window_causal_mask,
    build_prefix_lm_mask,
    attention_mask_from_lengths,
    lengths_from_attention_mask,
)
from .masking import build_block_causal_mask, build_dilated_causal_mask
from .masking import invert_mask, as_bool_mask, window_pattern_from_spans
from .positional import (
    build_rope_cache,
    apply_rotary,
    apply_rotary_scaled,
    build_alibi_bias,
    alibi_slopes,
    build_relative_position_indices,
    relative_position_bias_from_table,
    relative_position_bucket,
    build_sinusoidal_cache,
    rope_ntk_scaling,
    rope_yarn_factors,
    rescale_positions,
    build_rope_cache_2d,
    apply_rotary_2d,
    fit_alibi_slopes,
    rotary_fft,
)
from .residual import residual_add, gated_residual_add, residual_bias_dropout_add, prenorm, postnorm
from .init import xavier_uniform_linear, kaiming_uniform_linear, mu_param_linear_init_, deepnet_residual_scale, init_swiglu_bias, zero_out_proj_bias, init_rmsnorm_, mu_param_conv_init_, xavier_fanfix_linear, scaled_silu_init_, ntk_rescale, fan_in_dynamic, init_schedules
from .numerics import safe_softmax, masked_log_softmax, masked_logsumexp
from .numerics import (
    log1mexp,
    expm1_clip,
    softplus_safe,
    safe_sigmoid,
    safe_tanh,
    log_sigmoid_safe,
    welford_update,
    finite_mask,
    nan_to_num_,
    global_l2_norm,
    scale_logits,
    clamp_logits,
    mask_topk,
    mask_topp,
    hyperbolic_project,
    percentile_scale,
    mse_scale,
    range_track,
    roofline,
    inclusive_scan,
    exclusive_scan,
    stable_cumprod,
    fft_conv1d,
    dct,
    idct,
    hilbert_transform,
    bilinear_discretize,
    zoh_discretize,
    ssm_step,
    ssm_stability_margin,
    power_spectrum,
    power_spectrum_generic,
    clip_unit_sphere,
    proj_simplex,
    proj_psd,
    assert_finite,
    nan_guard,
    accum_steps,
    microbatch_plan,
    bucket_sizes,
    tensor_shards,
    estimate_bytes,
    activation_bytes,
    flops_linear,
    flops_conv1d,
    flops_conv2d,
    params_count_linear,
    time_op,
    ema_range_track,
)
from .regularization import drop_path, StochasticDepth, z_loss_from_logits, label_smooth, grad_noise_std, build_tokendrop_mask, build_sequencedrop_mask, prune_topk_, magnitude_mask, mixout, stochastic_depth_mask
from .shape import ensure_even_last_dim, split_heads, merge_heads
from .shape import split_qkv, merge_qkv, center_pad, pad_to_multiple, right_trim_to, assert_mask_shape, assert_boolean_mask, assert_broadcastable, split_gqa_heads, merge_gqa_heads, ensure_contiguous_lastdim, reorder_to_channels_last_2d, stride_equal, is_view_of, expect_shape, same_shape, enforce_static_shape, trace_shape, expect_memory_format, bhdt_to_bthd, contiguous_lastdim, assert_shape, assert_mask, pack_heads, unpack_heads, rechunk, S, unify, graph_shapes, infer, broadcast_plan, tile, reorder
from .dtypes import cast_for_softmax, cast_for_norm, restore_dtype, to_dtype_like, is_fp16, is_bf16, is_int8, is_fp8, cast_logits_for_loss, set_matmul_precision, maybe_autocast, expect_dtype, promote_mixed, amp_policy_for_op, fp8_dynamic_scale_update
from .dtypes import FP8AmaxTracker, fp8_scale_from_amax, with_logits_precision
from .losses import masked_cross_entropy, sequence_nll, masked_cross_entropy_ls, masked_kl_div, masked_js_div, sequence_nll_zloss, masked_mse, masked_huber, masked_perplexity, bce_with_logits_masked, nll_tokenwise, masked_label_margin_loss, masked_log_score, masked_spherical_loss
from .random import seed_everything, set_deterministic, philox_stream, rng_scope, dropout_mask
from .ragged import pack_sequences, unpack_sequences, segment_sum as ragged_segment_sum, segment_mean as ragged_segment_mean, segment_max as ragged_segment_max, segment_min as ragged_segment_min, ragged_gather
from .ragged import packed_softmax as ragged_packed_softmax, packed_logsumexp as ragged_packed_logsumexp, ragged_inclusive_cumsum, ragged_exclusive_cumsum, ragged_scatter
from .sampling import apply_temperature, apply_repetition_penalty, apply_min_p_mask, apply_typical_mask, mixture_of_logits, ban_tokens, force_tokens, apply_min_tokens_to_keep_mask, apply_topk_mask, apply_topp_mask, apply_tfs_mask, apply_eta_mask, mirostat_state, mirostat_update, apply_stop_phrases_mask, json_schema_mask, cfgrammar_mask, sample_gumbel, gumbel_topk, gumbel_softmax
from .numerics import kahan_sum, safe_softmax_with_logsumexp
from .numerics import masked_mean, masked_var, masked_std, masked_softmax, l2_normalize, assert_fp32_for_loss, log1pexp_safe, logaddexp_many, softmax_zloss, segment_logsumexp, logcumsumexp, masked_cumsum, masked_cummax, expm1mexp_safe, logdiffexp, banded_mm, triangular_mask_mm, pinv_safe, solve_cholesky_safe, assert_prob_simplex
from .metrics import masked_accuracy, masked_token_f1, masked_topk_accuracy, ece_binning, sequence_logprob, distinct_n, self_bleu, brier_score_masked, ece_temperature_sweep, sequence_entropy, uniq_ngrams, masked_span_f1, calibrate_temperature_grid, plascale_logits, vector_scale_logits
from .export_safe import gelu_export, rmsnorm_export, gather2d_export, scatter_add_export, gather1d_export
from .shard import tp_linear_partition, kv_partition, estimate_activation_bytes, attn_flops, mlp_flops, tensor_bytes, estimate_latency_attn, allreduce_, reduce_scatter, allgather, shard_linear_weight, seq_alltoall, seq_partition, seq_gather_restore, shard_mlp_weight, expert_router_plan, act_partition_plan, reassemble_acts, estimate_activation_bytes_per_token
from .windows import window_partition, window_merge, ring_buffer_indices
from .compile import allow_in_graph, masked_fill_where, infer_attn_shapes, graph_safe_seed, record_stream_guard, cuda_graph_seed_scope, nccl_stream_guard, overlap_copy_compute, cuda_graph_warmup, graph_replay_step, custom_grad, stop_grad
from .numerics import chunked_softmax, blockwise_logsumexp, masked_softmax_chunked, chunked_norm
from .optim import (
    grad_norm_parameters,
    clip_grad_norm_,
    assert_no_nan_grad,
    loss_scaler_step_safe,
    unitwise_l2_norm,
    unitwise_clip_,
    clip_grad_value_,
    global_grad_norm_fp32,
    clip_grad_norm_masked_,
    decoupled_weight_decay_,
    decay_mask_from_names,
    apply_weight_decay_masked_,
    zero_nan_inf_grad_,
    gradient_centralization_,
    project_grad_orthogonal_,
    add_grad_noise_,
    ema_update_,
    ema_compute_decay,
    swa_merge_,
    sam_perturbation_,
    sam_restore_,
    schedule_linear_with_warmup,
    schedule_cosine_with_warmup,
    schedule_poly,
    schedule_piecewise,
    reduce_grad_norm,
    bucketed_grad_norm,
    grad_norm_report,
    assert_global_norm_below,
    adamw_update_,
    lamb_update_,
    lion_update_,
    adafactor_update_,
    clip_by_policy_,
    loss_scale_update_,
    unscale_grads_,
    detect_overflow,
    decay_mask_from_params,
    apply_weight_decay_routed_,
    sam_compute_rho_,
    asam_scale_,
    sam_should_skip,
    ema_update_bc_,
    swa_collect_,
    swa_finalize_,
    schedule_cosine_restart,
    schedule_linear_floor,
)
from .quant_utils import quant_scale_per_channel, pack_int8_weight_linear, QuantMeta, groupwise_absmax, fold_scales, unfold_scales, hist_calibrator, mse_calibrator, int8_clip_activation_
from .sampling import build_regex_constraint_mask, apply_no_repeat_ngram_mask, apply_presence_frequency_penalty
from .lowrank import svd_lowrank, factorized_linear, rank_selective_update_
from .arena import TensorArena
from .checkpoint import remat, checkpoint_sequential
from .io_utils import pin_if_cpu, async_to_device
from .io_safetensors import safetensor_dump, safetensor_load, stable_tensor_hash
from .einsum import plan_einsum
from .debug import install_nan_guard, detect_fp16_overflow, bitwise_equal_forward, assert_reproducible_step, numeric_grad_check, nan_window_scan, assert_same_rng_scope, gradcheck_stateless
from .sparse import blocksparse_mask, bsr_mm, sparsify_topk, magnitude_prune

__all__ = [
    "RMSNorm",
    "MLP",
    "ScaleNorm",
    "masked_rmsnorm",
    "rmsnorm",
    "layer_norm",
    "mean_only_layer_norm",
    "lp_norm",
    "power_norm",
    "chunked_rmsnorm",
    "spectral_norm",
    "weight_norm",
    "orthogonalize",
    "rolling_norm",
    "online_rms",
    "gelu",
    "silu",
    "bias_gelu",
    "bias_silu",
    "fast_gelu",
    "quick_gelu",
    "mish",
    "tanh_gelu",
    "swiglu",
    "geglu",
    "reglu",
    "build_causal_mask",
    "build_padding_mask",
    "apply_mask",
    "broadcast_mask",
    "build_sliding_window_causal_mask",
    "build_block_causal_mask",
    "build_dilated_causal_mask",
    "build_prefix_lm_mask",
    "attention_mask_from_lengths",
    "lengths_from_attention_mask",
    "build_rope_cache",
    "apply_rotary",
    "apply_rotary_scaled",
    "build_alibi_bias",
    "alibi_slopes",
    "build_relative_position_indices",
    "relative_position_bias_from_table",
    "relative_position_bucket",
    "build_sinusoidal_cache",
    "rope_ntk_scaling",
    "rope_yarn_factors",
    "rescale_positions",
    "build_rope_cache_2d",
    "apply_rotary_2d",
    "fit_alibi_slopes",
    "rotary_fft",
    "residual_add",
    "gated_residual_add",
    "residual_bias_dropout_add",
    "prenorm",
    "postnorm",
    "xavier_uniform_linear",
    "kaiming_uniform_linear",
    "mu_param_linear_init_",
    "deepnet_residual_scale",
    "init_swiglu_bias",
    "zero_out_proj_bias",
    "init_rmsnorm_",
    "mu_param_conv_init_",
    "xavier_fanfix_linear",
    "scaled_silu_init_",
    "ntk_rescale",
    "fan_in_dynamic",
    "init_schedules",
    "safe_softmax",
    "masked_log_softmax",
    "masked_logsumexp",
    "log1mexp",
    "expm1_clip",
    "softplus_safe",
    "safe_sigmoid",
    "safe_tanh",
    "log_sigmoid_safe",
    "welford_update",
    "finite_mask",
    "nan_to_num_",
    "global_l2_norm",
    "scale_logits",
    "clamp_logits",
    "mask_topk",
    "mask_topp",
    "hyperbolic_project",
    "percentile_scale",
    "mse_scale",
    "range_track",
    "roofline",
    "inclusive_scan",
    "exclusive_scan",
    "stable_cumprod",
    "fft_conv1d",
    "dct",
    "idct",
    "hilbert_transform",
    "bilinear_discretize",
    "zoh_discretize",
    "ssm_step",
    "ssm_stability_margin",
    "power_spectrum",
    "power_spectrum_generic",
    "clip_unit_sphere",
    "proj_simplex",
    "proj_psd",
    "assert_finite",
    "nan_guard",
    "accum_steps",
    "microbatch_plan",
    "bucket_sizes",
    "tensor_shards",
    "estimate_bytes",
    "activation_bytes",
    "flops_linear",
    "flops_conv1d",
    "flops_conv2d",
    "params_count_linear",
    "time_op",
    "ema_range_track",
    "drop_path",
    "StochasticDepth",
    "z_loss_from_logits",
    "label_smooth",
    "grad_noise_std",
    "build_tokendrop_mask",
    "build_sequencedrop_mask",
    "prune_topk_",
    "magnitude_mask",
    "mixout",
    "stochastic_depth_mask",
    "ensure_even_last_dim",
    "split_heads",
    "merge_heads",
    "split_qkv",
    "merge_qkv",
    "center_pad",
    "bhdt_to_bthd",
    "contiguous_lastdim",
    "assert_shape",
    "assert_mask",
    "pack_heads",
    "unpack_heads",
    "rechunk",
    "S",
    "unify",
    "graph_shapes",
    "infer",
    "broadcast_plan",
    "tile",
    "reorder",
    "ensure_contiguous_lastdim",
    "reorder_to_channels_last_2d",
    "stride_equal",
    "is_view_of",
    "expect_shape",
    "same_shape",
    "enforce_static_shape",
    "trace_shape",
    "expect_memory_format",
    "split_gqa_heads",
    "merge_gqa_heads",
    "assert_mask_shape",
    "assert_boolean_mask",
    "assert_broadcastable",
    "cast_for_softmax",
    "cast_for_norm",
    "restore_dtype",
    "to_dtype_like",
    "is_fp16",
    "is_bf16",
    "is_int8",
    "is_fp8",
    "cast_logits_for_loss",
    "set_matmul_precision",
    "maybe_autocast",
    "expect_dtype",
    "promote_mixed",
    "amp_policy_for_op",
    "fp8_dynamic_scale_update",
    "FP8AmaxTracker",
    "fp8_scale_from_amax",
    "with_logits_precision",
    "masked_cross_entropy",
    "sequence_nll",
    "masked_cross_entropy_ls",
    "masked_kl_div",
    "masked_js_div",
    "sequence_nll_zloss",
    "masked_mse",
    "masked_huber",
    "masked_perplexity",
    "seed_everything",
    "set_deterministic",
    "philox_stream",
    "rng_scope",
    "dropout_mask",
    "pack_sequences",
    "unpack_sequences",
    "ragged_segment_sum",
    "ragged_segment_mean",
    "ragged_segment_max",
    "ragged_segment_min",
    "ragged_gather",
    "ragged_scatter",
    "ragged_packed_softmax",
    "ragged_packed_logsumexp",
    "ragged_inclusive_cumsum",
    "ragged_exclusive_cumsum",
    "apply_temperature",
    "apply_repetition_penalty",
    "apply_min_p_mask",
    "apply_typical_mask",
    "apply_tfs_mask",
    "apply_eta_mask",
    "mirostat_state",
    "mirostat_update",
    "apply_stop_phrases_mask",
    "json_schema_mask",
    "cfgrammar_mask",
    "mixture_of_logits",
    "ban_tokens",
    "force_tokens",
    "apply_min_tokens_to_keep_mask",
    "apply_topk_mask",
    "apply_topp_mask",
    "sample_gumbel",
    "gumbel_topk",
    "gumbel_softmax",
    "kahan_sum",
    "safe_softmax_with_logsumexp",
    "masked_mean",
    "masked_var",
    "masked_std",
    "masked_softmax",
    "l2_normalize",
    "assert_fp32_for_loss",
    "log1pexp_safe",
    "logaddexp_many",
    "softmax_zloss",
    "segment_logsumexp",
    "logcumsumexp",
    "masked_cumsum",
    "masked_cummax",
    "expm1mexp_safe",
    "logdiffexp",
    "banded_mm",
    "triangular_mask_mm",
    "pinv_safe",
    "solve_cholesky_safe",
    "assert_prob_simplex",
    "masked_accuracy",
    "masked_token_f1",
    "ece_binning",
    "sequence_logprob",
    "distinct_n",
    "self_bleu",
    "brier_score_masked",
    "ece_temperature_sweep",
    "sequence_entropy",
    "uniq_ngrams",
    "masked_span_f1",
    "calibrate_temperature_grid",
    "plascale_logits",
    "vector_scale_logits",
    "gelu_export",
    "rmsnorm_export",
    "gather2d_export",
    "gather1d_export",
    "scatter_add_export",
    "tp_linear_partition",
    "kv_partition",
    "estimate_activation_bytes",
    "window_partition",
    "window_merge",
    "ring_buffer_indices",
    "invert_mask",
    "as_bool_mask",
    "window_pattern_from_spans",
    "pad_to_multiple",
    "right_trim_to",
    "masked_topk_accuracy",
    "bce_with_logits_masked",
    "nll_tokenwise",
    "masked_label_margin_loss",
    "masked_log_score",
    "masked_spherical_loss",
    "attn_flops",
    "mlp_flops",
    "tensor_bytes",
    "estimate_latency_attn",
    "seq_alltoall",
    "seq_partition",
    "seq_gather_restore",
    "shard_mlp_weight",
    "expert_router_plan",
    "act_partition_plan",
    "reassemble_acts",
    "estimate_activation_bytes_per_token",
    "allreduce_",
    "reduce_scatter",
    "allgather",
    "shard_linear_weight",
    "allow_in_graph",
    "masked_fill_where",
    "infer_attn_shapes",
    "graph_safe_seed",
    "cuda_graph_seed_scope",
    "nccl_stream_guard",
    "overlap_copy_compute",
    "cuda_graph_warmup",
    "graph_replay_step",
    "custom_grad",
    "stop_grad",
    "record_stream_guard",
    "chunked_softmax",
    "blockwise_logsumexp",
    "masked_softmax_chunked",
    "chunked_norm",
    "grad_norm_parameters",
    "clip_grad_norm_",
    "assert_no_nan_grad",
    "loss_scaler_step_safe",
    "unitwise_l2_norm",
    "unitwise_clip_",
    "clip_grad_value_",
    "global_grad_norm_fp32",
    "clip_grad_norm_masked_",
    "decoupled_weight_decay_",
    "decay_mask_from_names",
    "apply_weight_decay_masked_",
    "zero_nan_inf_grad_",
    "gradient_centralization_",
    "project_grad_orthogonal_",
    "add_grad_noise_",
    "ema_update_",
    "ema_compute_decay",
    "swa_merge_",
    "sam_perturbation_",
    "sam_restore_",
    "schedule_linear_with_warmup",
    "schedule_cosine_with_warmup",
    "schedule_poly",
    "schedule_piecewise",
    "reduce_grad_norm",
    "bucketed_grad_norm",
    "grad_norm_report",
    "assert_global_norm_below",
    "adamw_update_",
    "lamb_update_",
    "lion_update_",
    "adafactor_update_",
    "clip_by_policy_",
    "loss_scale_update_",
    "unscale_grads_",
    "detect_overflow",
    "decay_mask_from_params",
    "apply_weight_decay_routed_",
    "sam_compute_rho_",
    "asam_scale_",
    "sam_should_skip",
    "ema_update_bc_",
    "swa_collect_",
    "swa_finalize_",
    "schedule_cosine_restart",
    "schedule_linear_floor",
    "quant_scale_per_channel",
    "pack_int8_weight_linear",
    "QuantMeta",
    "groupwise_absmax",
    "fold_scales",
    "unfold_scales",
    "hist_calibrator",
    "mse_calibrator",
    "int8_clip_activation_",
    "build_regex_constraint_mask",
    "apply_no_repeat_ngram_mask",
    "apply_presence_frequency_penalty",
    "svd_lowrank",
    "factorized_linear",
    "rank_selective_update_",
    "TensorArena",
    "remat",
    "checkpoint_sequential",
    "pin_if_cpu",
    "async_to_device",
    "safetensor_dump",
    "safetensor_load",
    "stable_tensor_hash",
    "plan_einsum",
    "install_nan_guard",
    "detect_fp16_overflow",
    "bitwise_equal_forward",
    "assert_reproducible_step",
    "numeric_grad_check",
    "nan_window_scan",
    "assert_same_rng_scope",
    "gradcheck_stateless",
    "blocksparse_mask",
    "bsr_mm",
    "sparsify_topk",
    "magnitude_prune",
]


